---
title: "Modification indices"
author: Mauricio Garnier-Villarreal
bibliography:
  - refs.bib
---

```{r pkgld, include=FALSE}
library(blavaan, quietly=TRUE)
library(lavaan, quietly=TRUE)
```

### Introduction
In SEM, one of the first steps is to evaluate the model's global fit. After global fit, we need to evaluate the local fit of a model, meaning how does the model reproduces specific indicator correlatons. 

There are a couple of common methods for this, (a) test for high residual correlations, or (b) modification indices. This tutorial focuses on the second. Modification indices test the **likely** change in the model if a single parameter is added to the model that was not originally included, and do this for every possible parameter that was not included [@bentler_fit_1990]. 

### Modification Indices

Modification indices present different **indices** to quantify the effect of each pararmeter, here we will focus on two, (a) the modification index (MI) or Lagrange multiplier, which provides an estimated value in which the modelâ€™s chi-square ($\chi^2$) test statistic would decrease if a fixed parameter were added to the model and freely estimated, and (b) standardized expected parameter change (SEPC) which is the approximated standardized value if the parameter where to be estimated in the model [@whittaker_using_2012]. 

MI presents the possible effect on the overall model, and SEPC presents the effect size for the missed parameter. 

We will show an example with the @holswi39 example. You first estimate your SEM/CFA model as usual

```{r, eval=T, include=FALSE, cache=TRUE}
HS.model <- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit <- bcfa(HS.model, data=HolzingerSwineford1939, std.lv=TRUE)
```

```{r, eval=F}
HS.model <- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit <- bcfa(HS.model, data=HolzingerSwineford1939, std.lv=TRUE)
```


Then we would need to write a **discrepancy** function to collect the modification indices. This function estimates and save the MI and SEPC

```{r, eval=T, include=T}
discFUN <- list(mod.ind_mi = function(object){
  temp <- modificationindices(object,free.remove = F)
  mods <- temp$mi
  names(mods) <- paste0(temp$lhs,temp$op,temp$rhs)
  return(mods)
},
mod.ind_sepc.all = function(object){
  temp <- modificationindices(object,free.remove = F)
  sepc.all <- temp$sepc.all
  names(sepc.all) <- paste0(temp$lhs,temp$op,temp$rhs)
  return(sepc.all )
}
)
```

Then we will pass this function to the ```ppmc()``` function of *blavaan*, this way the MI and SEPC will be estimated at each iteration of the saved posterior draws, building posterior distributions for them

```{r, eval=T, include=FALSE, cache=TRUE}
out <- ppmc(fit, discFUN = discFUN)
```

```{r, eval=F, include=T}
out <- ppmc(fit, discFUN = discFUN)
```

Then we view the top 5 parameters arrange by the mean (EAP) MI, which in thos case shows that the most the parameter that would have the highest impact in overall model fit (according to EAP) is **visual=~x9** the cross-loading from item **x9** to the factor Visual

```{r, eval=T, include=T}
summary(out, prob=.9, discFUN = "mod.ind_mi", sort.by="EAP", decreasing=T)[1:5,]
```

But accoridng to the median, the parameter that would have the highest impact owuld be **x7~~x8** the residual corretion between indicators **x7** and **x8**

```{r, eval=T, include=T}
summary(out, prob=.9, discFUN = "mod.ind_mi", sort.by="Median", decreasing=T)[1:5,]
```

MI is still recommended as the best metric to indicate which parameter is best to include next, and can use the SEPC to evaluate the **likely** effect size for the respecive parameters

```{r, eval=T, include=T}
summary(out, prob=.9, discFUN = "mod.ind_sepc.all", sort.by="EAP", decreasing=T)[1:5,]
```

Here we see that for the 2 highest parameters, the likely SEPC is **x7~~x8 = 0.788** and **visual=~x9 = 0.519**. With this information we can decide to include one of these new parameters in the model (one at the time). For this example, since factor loadings have impact in more variances and covariances of the covariance matrix I would choose **visual=~x9**

```{r, eval=T, include=FALSE, cache=TRUE}
HS.model <- ' visual  =~ x1 + x2 + x3 + x9
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit2 <- bcfa(HS.model, data=HolzingerSwineford1939, std.lv=TRUE)
```


```{r, eval=F}
HS.model <- ' visual  =~ x1 + x2 + x3 + x9
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit2 <- bcfa(HS.model, data=HolzingerSwineford1939, std.lv=TRUE)
```

And you can check if the added parameter has the expected impact in overall fit with the ```blavFitIndices()``` function, and the ```summary()```

It is important to consider also the theoretical relevance of the suggested parameters, make sure that it makes sense, instead of just adding parameters until having **good** fit.

### Summary

In this tutorials we show how to calculate the MI and SEPC across posterior distributions, and evaluate which parameters can be added. 

With the ```ppmc()``` function we are able to calculate relevant information after model estimation, and build posterior distributions of them. 

The general recommendations are to use MI to identify the most likely parameter to add, and SEPC as the effect size of the new parameter. 

### References
